{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-24T06:41:57.560291Z","iopub.execute_input":"2023-02-24T06:41:57.561166Z","iopub.status.idle":"2023-02-24T06:41:57.583803Z","shell.execute_reply.started":"2023-02-24T06:41:57.561081Z","shell.execute_reply":"2023-02-24T06:41:57.582934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import annotations\n\nfrom tqdm.notebook import tqdm\nfrom collections import OrderedDict\nimport glob\nimport cv2\nimport random\n\nfrom torchvision.io import read_image\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torch import nn\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:41:57.586053Z","iopub.execute_input":"2023-02-24T06:41:57.587039Z","iopub.status.idle":"2023-02-24T06:42:00.061918Z","shell.execute_reply.started":"2023-02-24T06:41:57.586983Z","shell.execute_reply":"2023-02-24T06:42:00.059976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fix random seed","metadata":{}},{"cell_type":"code","source":"def fix_seed(seed):\n    # random\n    random.seed(seed)\n#     # Numpy\n#     np.random.seed(seed)\n    # Pytorch\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n#     # Tensorflow\n#     tf.random.set_seed(seed)\n\nSEED = 3407\nfix_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:42:00.064718Z","iopub.execute_input":"2023-02-24T06:42:00.065285Z","iopub.status.idle":"2023-02-24T06:42:00.075577Z","shell.execute_reply.started":"2023-02-24T06:42:00.065245Z","shell.execute_reply":"2023-02-24T06:42:00.074390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load test dataset","metadata":{}},{"cell_type":"code","source":"# Test data\ntest_target = pd.read_csv('/kaggle/input/aptos2019-blindness-detection/test.csv')\ntest_target[\"diagnosis\"] = \"0\"\ntest_target = test_target.astype({\"diagnosis\": \"int64\"})","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:42:00.077350Z","iopub.execute_input":"2023-02-24T06:42:00.078321Z","iopub.status.idle":"2023-02-24T06:42:00.118285Z","shell.execute_reply.started":"2023-02-24T06:42:00.078284Z","shell.execute_reply":"2023-02-24T06:42:00.117084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define dataset and dataloader","metadata":{}},{"cell_type":"code","source":"# # Preprocess images\nresize_h = 224\nresize_w = 224\ninput_shape = (resize_h, resize_w)\nprint(resize_h, resize_w)","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:42:00.123630Z","iopub.execute_input":"2023-02-24T06:42:00.124101Z","iopub.status.idle":"2023-02-24T06:42:00.131900Z","shell.execute_reply.started":"2023-02-24T06:42:00.124062Z","shell.execute_reply":"2023-02-24T06:42:00.130807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define dataset\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, img_labels: pd.DataFrame, img_dir, transform=None, target_transform=None):\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n        self.img_labels = img_labels\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0] + \".png\")\n        image = read_image(img_path)\n        label = self.img_labels.iloc[idx, 1]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:42:00.133411Z","iopub.execute_input":"2023-02-24T06:42:00.134138Z","iopub.status.idle":"2023-02-24T06:42:00.148793Z","shell.execute_reply.started":"2023-02-24T06:42:00.134103Z","shell.execute_reply":"2023-02-24T06:42:00.147547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mean = imgs.view(3, -1).mean(dim=1)\nmean = (0.4138, 0.2210, 0.0737)\nprint(mean)","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:42:00.150427Z","iopub.execute_input":"2023-02-24T06:42:00.151058Z","iopub.status.idle":"2023-02-24T06:42:00.163210Z","shell.execute_reply.started":"2023-02-24T06:42:00.150999Z","shell.execute_reply":"2023-02-24T06:42:00.162214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# std = imgs.view(3, -1).std(dim=1)\nstd = (0.2745, 0.1499, 0.0808)\nprint(std)","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:42:00.164385Z","iopub.execute_input":"2023-02-24T06:42:00.164947Z","iopub.status.idle":"2023-02-24T06:42:00.177397Z","shell.execute_reply.started":"2023-02-24T06:42:00.164906Z","shell.execute_reply":"2023-02-24T06:42:00.176061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (resize_h, resize_w)\n        \ndata_transforms = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n    transforms.Resize(input_shape),\n    transforms.Normalize(mean, std)\n])\n\ntest_data = CustomImageDataset(test_target, \"/kaggle/input/aptos2019-blindness-detection/test_images\", data_transforms)","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:42:00.179301Z","iopub.execute_input":"2023-02-24T06:42:00.179760Z","iopub.status.idle":"2023-02-24T06:42:00.187520Z","shell.execute_reply.started":"2023-02-24T06:42:00.179722Z","shell.execute_reply":"2023-02-24T06:42:00.186340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader_test = torch.utils.data.DataLoader(\n    test_data,\n    batch_size=1,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:42:00.189181Z","iopub.execute_input":"2023-02-24T06:42:00.190021Z","iopub.status.idle":"2023-02-24T06:42:00.197260Z","shell.execute_reply.started":"2023-02-24T06:42:00.189973Z","shell.execute_reply":"2023-02-24T06:42:00.195971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load model","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nmodel = torch.load('/kaggle/input/aptos-resnet34-without-prior-fine-tuning/resnet34.pth') # load the entire model with weight parameters, trained with trainval data in addition to fine tuning, so far resnet34 trained with trainval data without fine tuning works best\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:42:00.200828Z","iopub.execute_input":"2023-02-24T06:42:00.201812Z","iopub.status.idle":"2023-02-24T06:42:04.569334Z","shell.execute_reply.started":"2023-02-24T06:42:00.201766Z","shell.execute_reply":"2023-02-24T06:42:04.568369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test the model","metadata":{}},{"cell_type":"code","source":"model.eval()\n\nt_pred = []\nfor x, _ in tqdm(dataloader_test):\n    \n    x = x.to(device)\n    y = model.forward(x)\n    pred = y.argmax(1)\n    preds = pred.to(\"cpu\").detach().numpy()\n    t_pred.append(preds)\n#     for result in preds:\n#         t_pred.append(result)\n    \n#     acc = torch.where(t - pred.to(\"cpu\") == 0, torch.ones_like(t), torch.zeros_like(t))\n#     test_num += acc.size()[0]\n#     test_true_num += acc.sum().item()\n\n# print(\"Accuracy on test set: {:.3f}\".format(test_true_num/test_num))","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:42:04.570703Z","iopub.execute_input":"2023-02-24T06:42:04.571089Z","iopub.status.idle":"2023-02-24T06:45:19.434199Z","shell.execute_reply.started":"2023-02-24T06:42:04.571052Z","shell.execute_reply":"2023-02-24T06:45:19.433231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/aptos2019-blindness-detection/sample_submission.csv')\nsubmission['diagnosis'] = np.array(t_pred, dtype='int64').flatten()\n\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:45:19.435682Z","iopub.execute_input":"2023-02-24T06:45:19.436277Z","iopub.status.idle":"2023-02-24T06:45:19.462613Z","shell.execute_reply.started":"2023-02-24T06:45:19.436239Z","shell.execute_reply":"2023-02-24T06:45:19.461739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['diagnosis'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:45:19.464060Z","iopub.execute_input":"2023-02-24T06:45:19.464394Z","iopub.status.idle":"2023-02-24T06:45:19.477263Z","shell.execute_reply.started":"2023-02-24T06:45:19.464360Z","shell.execute_reply":"2023-02-24T06:45:19.476068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['diagnosis'].value_counts().plot(kind='bar')\nplt.title('Class counts')","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:45:19.479079Z","iopub.execute_input":"2023-02-24T06:45:19.479493Z","iopub.status.idle":"2023-02-24T06:45:19.718164Z","shell.execute_reply.started":"2023-02-24T06:45:19.479448Z","shell.execute_reply":"2023-02-24T06:45:19.717273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:45:19.719569Z","iopub.execute_input":"2023-02-24T06:45:19.719916Z","iopub.status.idle":"2023-02-24T06:45:19.729868Z","shell.execute_reply.started":"2023-02-24T06:45:19.719880Z","shell.execute_reply":"2023-02-24T06:45:19.729059Z"},"trusted":true},"execution_count":null,"outputs":[]}]}