{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14774,"databundleVersionId":875431,"sourceType":"competition"}],"dockerImageVersionId":30397,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import annotations\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nfrom tqdm.notebook import tqdm\nfrom collections import OrderedDict\nimport glob\nimport cv2\nimport random\nimport time, datetime\nimport copy\n\nfrom torchvision.io import read_image\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torch import nn\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data.sampler import WeightedRandomSampler\nfrom torch.utils.data.dataset import Subset\n\nimport json\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report\nfrom collections import Counter","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:33.39939Z","iopub.execute_input":"2023-03-15T14:04:33.399701Z","iopub.status.idle":"2023-03-15T14:04:36.704643Z","shell.execute_reply.started":"2023-03-15T14:04:33.399628Z","shell.execute_reply":"2023-03-15T14:04:36.703503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fix random seed","metadata":{}},{"cell_type":"code","source":"def fix_seed(seed):\n    # random\n    random.seed(seed)\n#     # Numpy\n#     np.random.seed(seed)\n    # Pytorch\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.use_deterministic_algorithms = True\n#     # Tensorflow\n#     tf.random.set_seed(seed)\n\nSEED = 3407\nfix_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:36.707979Z","iopub.execute_input":"2023-03-15T14:04:36.708616Z","iopub.status.idle":"2023-03-15T14:04:36.717371Z","shell.execute_reply.started":"2023-03-15T14:04:36.708574Z","shell.execute_reply":"2023-03-15T14:04:36.716448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load dataset","metadata":{}},{"cell_type":"code","source":"# Train data\ntrain_target = pd.read_csv('/kaggle/input/aptos2019-blindness-detection/train.csv')\n\n# train_target['diagnosis'].value_counts().plot(kind='bar');\n# plt.title('Class counts');\n\n# does this affect git?","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:36.718768Z","iopub.execute_input":"2023-03-15T14:04:36.719214Z","iopub.status.idle":"2023-03-15T14:04:36.745692Z","shell.execute_reply.started":"2023-03-15T14:04:36.719178Z","shell.execute_reply":"2023-03-15T14:04:36.744237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# paths = glob.glob(r'/kaggle/input/aptos2019-blindness-detection/train_images/*.png')\n# widths = []\n# heights = []\n\n# for path in tqdm(paths):\n#     img = cv2.imread(path)\n#     h, w = img.shape[:2]\n    \n#     widths.append(w)\n#     heights.append(h)\n    \n# heights, widths = zip(*[cv2.imread(path).shape[:2] for path in tqdm(paths)])","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:36.751748Z","iopub.execute_input":"2023-03-15T14:04:36.752391Z","iopub.status.idle":"2023-03-15T14:04:36.761023Z","shell.execute_reply.started":"2023-03-15T14:04:36.752346Z","shell.execute_reply":"2023-03-15T14:04:36.757771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.hist(heights, bins = 10)\n# plt.title('heights')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:36.762509Z","iopub.execute_input":"2023-03-15T14:04:36.762836Z","iopub.status.idle":"2023-03-15T14:04:36.774802Z","shell.execute_reply.started":"2023-03-15T14:04:36.762801Z","shell.execute_reply":"2023-03-15T14:04:36.773728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.hist(widths, bins = 10)\n# plt.title('widths')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:36.77659Z","iopub.execute_input":"2023-03-15T14:04:36.777369Z","iopub.status.idle":"2023-03-15T14:04:36.785412Z","shell.execute_reply.started":"2023-03-15T14:04:36.777333Z","shell.execute_reply":"2023-03-15T14:04:36.784425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define dataset and dataloader","metadata":{}},{"cell_type":"code","source":"# # Preprocess images\nresize_h = 224\nresize_w = 224\ninput_shape = (resize_h, resize_w)\n# # train_images = list()\n# # for path in paths:\n# #     img = cv2.imread(path)\n# #     img = cv2.resize(img, dsize=(resize_h, resize_w))\n# #     train_images.append(img)\nprint(resize_h, resize_w)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:36.787244Z","iopub.execute_input":"2023-03-15T14:04:36.790097Z","iopub.status.idle":"2023-03-15T14:04:36.80172Z","shell.execute_reply.started":"2023-03-15T14:04:36.790053Z","shell.execute_reply":"2023-03-15T14:04:36.800346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define dataset class\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, img_labels: pd.DataFrame, img_dir, transform=None, target_transform=None):\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n        self.img_labels = img_labels\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0] + \".png\")\n        image = read_image(img_path)\n        label = self.img_labels.iloc[idx, 1]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return image, label, idx","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:36.803488Z","iopub.execute_input":"2023-03-15T14:04:36.804891Z","iopub.status.idle":"2023-03-15T14:04:36.822902Z","shell.execute_reply.started":"2023-03-15T14:04:36.804857Z","shell.execute_reply":"2023-03-15T14:04:36.820931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pre_transforms = transforms.Compose([\n#     transforms.ToPILImage(),\n#     transforms.ToTensor(),\n#     transforms.Resize(input_shape)\n# ])\n\n# tensor_aptos = CustomImageDataset(train_target, \"/kaggle/input/aptos2019-blindness-detection/train_images\", pre_transforms)\n\n\n# imgs = torch.stack([img_t for img_t, _ in tqdm(tensor_aptos)], dim=3)\n# imgs.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:36.824475Z","iopub.execute_input":"2023-03-15T14:04:36.824958Z","iopub.status.idle":"2023-03-15T14:04:36.832965Z","shell.execute_reply.started":"2023-03-15T14:04:36.824923Z","shell.execute_reply":"2023-03-15T14:04:36.831907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mean = imgs.view(3, -1).mean(dim=1)\nmean = (0.4138, 0.2210, 0.0737)\nprint(mean)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:36.838706Z","iopub.execute_input":"2023-03-15T14:04:36.839025Z","iopub.status.idle":"2023-03-15T14:04:36.84525Z","shell.execute_reply.started":"2023-03-15T14:04:36.839Z","shell.execute_reply":"2023-03-15T14:04:36.844335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# std = imgs.view(3, -1).std(dim=1)\nstd = (0.2745, 0.1499, 0.0808)\nprint(std)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:36.848387Z","iopub.execute_input":"2023-03-15T14:04:36.848634Z","iopub.status.idle":"2023-03-15T14:04:36.85686Z","shell.execute_reply.started":"2023-03-15T14:04:36.84861Z","shell.execute_reply":"2023-03-15T14:04:36.855958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (resize_h, resize_w)\n\naugment_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.RandomRotation(degrees=180)\n])\n        \npreprocess_transforms = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n    transforms.Resize(input_shape),\n    transforms.Normalize(mean, std)\n])\n\n# train_img_path = \"/kaggle/input/aptos2019-blindness-detection/train_images\"\ntrain_img_path = \"/kaggle/input/aptos2019-blindness-detection/train_images\"\ntrainval_data = CustomImageDataset(train_target, train_img_path, preprocess_transforms)\n# X_train, X_val, y_train, y_val = train_test_split(train_target.index.values.tolist(), train_target['diagnosis'], test_size=0.2, shuffle=True, stratify=train_target['diagnosis'].values, random_state=3407)\n# val_size = round(len(trainval_data) * 0.2)\n# train_size = len(trainval_data) - val_size\n# # train_data, val_data = torch.utils.data.random_split(trainval_data, [train_size, val_size], generator=torch.manual_seed(3407))\n# train_data, val_data = Subset(trainval_data, X_train), Subset(trainval_data, X_val)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:36.858267Z","iopub.execute_input":"2023-03-15T14:04:36.858575Z","iopub.status.idle":"2023-03-15T14:04:36.888876Z","shell.execute_reply.started":"2023-03-15T14:04:36.858549Z","shell.execute_reply":"2023-03-15T14:04:36.888285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # sampler to balance the amount of samples in dataset\nlabels = train_target['diagnosis'].values\nclass_counts = torch.bincount(torch.tensor(labels))\nweights = 1. / class_counts.float()\nsample_weights = weights[labels]\nsampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:36.889918Z","iopub.execute_input":"2023-03-15T14:04:36.890786Z","iopub.status.idle":"2023-03-15T14:04:36.963797Z","shell.execute_reply.started":"2023-03-15T14:04:36.890751Z","shell.execute_reply":"2023-03-15T14:04:36.962364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# labels_map = {\n#     0: \"No\",\n#     1: \"Mi\",\n#     2: \"Mo\",\n#     3: \"Se\",\n#     4: \"Pr\"\n# }","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:36.965141Z","iopub.execute_input":"2023-03-15T14:04:36.967288Z","iopub.status.idle":"2023-03-15T14:04:36.975358Z","shell.execute_reply.started":"2023-03-15T14:04:36.967245Z","shell.execute_reply":"2023-03-15T14:04:36.974415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def display_images(dataset):\n#     figure = plt.figure(figsize=(10, 10))\n#     cols, rows = 10, 10\n#     for i in range(1, cols * rows + 1):\n#         sample_idx = torch.randint(len(dataset), size=(1,)).item()\n#         img, label = trainval_data[sample_idx]\n#         figure.add_subplot(rows, cols, i)\n#         plt.title(labels_map[label])\n#         plt.axis(\"off\")\n#         plt.imshow(img.squeeze().permute(1,2,0))\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:36.978346Z","iopub.execute_input":"2023-03-15T14:04:36.979047Z","iopub.status.idle":"2023-03-15T14:04:36.9881Z","shell.execute_reply.started":"2023-03-15T14:04:36.97901Z","shell.execute_reply":"2023-03-15T14:04:36.986904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TrainVal images\n# display_images(trainval_data)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:36.989719Z","iopub.execute_input":"2023-03-15T14:04:36.991038Z","iopub.status.idle":"2023-03-15T14:04:37.002295Z","shell.execute_reply.started":"2023-03-15T14:04:36.991003Z","shell.execute_reply":"2023-03-15T14:04:37.000668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test images\n# display_images(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:37.003723Z","iopub.execute_input":"2023-03-15T14:04:37.004409Z","iopub.status.idle":"2023-03-15T14:04:37.010626Z","shell.execute_reply.started":"2023-03-15T14:04:37.004373Z","shell.execute_reply":"2023-03-15T14:04:37.009733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define dataloader\n\nbatch_size = 64\n\nmethod = \"None\"\n\n# dataloader_train = torch.utils.data.DataLoader(\n#     train_data,\n#     batch_size=batch_size,\n#     # sampler=sampler\n#     shuffle=True\n# )\n\n# dataloader_valid = torch.utils.data.DataLoader(\n#     val_data,\n#     batch_size=batch_size,\n#     shuffle=True\n# )\n\ndataloader_trainval = torch.utils.data.DataLoader(\n    trainval_data,\n    batch_size=batch_size,\n    # sampler=sampler\n    shuffle=True\n)\n\n# dataloaders_dict = {'Train': dataloader_train, 'Validation': dataloader_valid}\n# dataloader_fine_tune = {'Train': dataloader_train}\ndataloader_dict = {'TrainVal': dataloader_trainval}","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:37.012172Z","iopub.execute_input":"2023-03-15T14:04:37.012823Z","iopub.status.idle":"2023-03-15T14:04:37.022035Z","shell.execute_reply.started":"2023-03-15T14:04:37.012787Z","shell.execute_reply":"2023-03-15T14:04:37.021163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define CNN model","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:37.023564Z","iopub.execute_input":"2023-03-15T14:04:37.024211Z","iopub.status.idle":"2023-03-15T14:04:37.03609Z","shell.execute_reply.started":"2023-03-15T14:04:37.024177Z","shell.execute_reply":"2023-03-15T14:04:37.035213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # modified code from https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n# def set_parameter_requires_grad(model, train):\n#     for param in model.parameters():\n#         param.requires_grad = train","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:37.038224Z","iopub.execute_input":"2023-03-15T14:04:37.039038Z","iopub.status.idle":"2023-03-15T14:04:37.046697Z","shell.execute_reply.started":"2023-03-15T14:04:37.039003Z","shell.execute_reply":"2023-03-15T14:04:37.045796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def weight_loss(weight, cost_sensitive=False):\n    loss = None\n    if cost_sensitive:\n        loss = nn.CrossEntropyLoss(weight=weight, reduction='mean')\n    else:\n        loss = nn.CrossEntropyLoss()\n    return loss, cost_sensitive","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_target['diagnosis'].values), y=train_target['diagnosis'].values)\nclass_weights=torch.tensor(class_weights,dtype=torch.float)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torchvision.models.densenet121(weights=torchvision.models.DenseNet121_Weights.DEFAULT)\nnum_ftrs = model.classifier.in_features\nmodel.classifier = nn.Linear(num_ftrs, 5)\n\noptimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0001)\ncriterion, cost_sensitive = weight_loss(class_weights, cost_sensitive=False) # according to an article\nscheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=32, eta_min=1e-4)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:37.048094Z","iopub.execute_input":"2023-03-15T14:04:37.048696Z","iopub.status.idle":"2023-03-15T14:04:37.698529Z","shell.execute_reply.started":"2023-03-15T14:04:37.048661Z","shell.execute_reply":"2023-03-15T14:04:37.69759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define train model","metadata":{}},{"cell_type":"code","source":"def train_model(model, device, dataloaders: dict, criterion, optimizer, scheduler=None, num_epochs=25, is_inception=False, augumented=False):\n    since = time.time()\n    \n    model = model.to(device)\n    criterion = criterion.to(device)\n    \n    histories = {'Accuracy': {phase: list() for phase in dataloaders.keys()}, 'Loss': {phase: list() for phase in dataloaders.keys()}}\n    f1_macro = list()\n    classification_reports = list()\n    \n    best_epoch = 20\n    best_score = 0\n    \n    terminate = False\n    \n    indices_set = set()\n    \n    class0, class1, class2, class3, class4, = 0, 0, 0, 0, 0\n\n    for epoch in range(num_epochs):\n        print('EPOCH: {}/{}'.format(epoch+1, num_epochs))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in dataloaders.keys():\n            if phase == 'Validation':\n                model.eval()   # Set model to evaluate mode\n            else:\n                model.train()  # Set model to training mode\n            \n            losses = []\n            num = 0\n            true_num = 0\n            \n            y_preds = []\n            y_trues = []\n\n            # Iterate over data.\n            for x, t, idx in tqdm(dataloaders[phase]):\n                model.zero_grad()  # Initialise gradient descent\n                if (phase == 'Train' or phase == 'TrainVal') and augumented:\n                    x = augment_transforms(x)\n                x, t = x.to(device), t.to(device)\n\n                # zero the parameter gradients\n                # optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'Train' or phase == 'TrainVal'):\n                    # Get model outputs and calculate loss\n                    # Special case for inception because in training it has an auxiliary output. In train\n                    #   mode we calculate the loss by summing the final output and the auxiliary output\n                    #   but in testing we only consider the final output.\n                    if is_inception and (phase == 'Train' or phase == 'TrainVal'):\n                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n                        y, aux_outputs = model(x)\n                        loss1 = criterion(y, t)\n                        loss2 = criterion(aux_outputs, t)\n                        loss = loss1 + 0.4*loss2\n                    else: # valid\n                        y = model(x)  # Forward propagation\n                        loss = criterion(y, t)\n\n                    pred = y.argmax(dim=1)  # 最大値を取るラベルを予測ラベルとする\n\n                    # backward + optimize only if in training phase\n                    if (phase == 'Train' or phase == 'TrainVal'):\n                        loss.backward()\n                        optimizer.step()\n                        \n                        counter = Counter(t.to(\"cpu\").tolist())\n                        class0 += counter[0]\n                        class1 += counter[1]\n                        class2 += counter[2]\n                        class3 += counter[3]\n                        class4 += counter[4]\n                        indices_set.update({*idx.numpy()})\n                        print(f'[0: {class0}], [1: {class1}], [2: {class2}], [3: {class3}], [4: {class4}], [data seen: {len(indices_set)}]')\n                    else:\n                        y_preds += pred.to(\"cpu\").tolist()\n                        y_trues+= t.to(\"cpu\").tolist()\n                        \n                    losses.append(loss.tolist())\n\n                    acc = torch.where(t.to(\"cpu\") - pred.to(\"cpu\") == 0, torch.ones_like(t).to(\"cpu\"), torch.zeros_like(t).to(\"cpu\"))\n                    num += acc.size()[0]\n                    true_num += acc.sum().item()\n                    \n            epoch_loss = np.mean(losses)\n            epoch_acc = true_num / num\n            \n            histories['Loss'][phase].append(epoch_loss)\n            histories['Accuracy'][phase].append(epoch_acc)\n            \n\n            print('{} [Loss: {:.4f}, Accuracy: {:.4f}]'.format(phase, epoch_loss, epoch_acc))\n            print()\n            scheduler.step()\n        \n        if terminate:\n            break\n        print()\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n\n    return model, num_epochs, best_epoch, histories, augumented, best_score, time_elapsed, f1_macro, classification_reports","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:37.729558Z","iopub.execute_input":"2023-03-15T14:04:37.729913Z","iopub.status.idle":"2023-03-15T14:04:37.752751Z","shell.execute_reply.started":"2023-03-15T14:04:37.729887Z","shell.execute_reply":"2023-03-15T14:04:37.751174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot(n_epochs, histories: dict):\n    epochs = np.arange(1, n_epochs + 1)\n\n    fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(8, 3))\n\n    for ax, metric in zip([ax1, ax2], histories.keys()):\n        ax.set_title(metric)\n        for key in histories[metric].keys():\n            ax.plot(epochs, histories[metric][key], label=key)\n        ax.set_xlabel(\"Epoch\")\n        ax.legend()\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:37.754192Z","iopub.execute_input":"2023-03-15T14:04:37.754745Z","iopub.status.idle":"2023-03-15T14:04:37.765075Z","shell.execute_reply.started":"2023-03-15T14:04:37.75471Z","shell.execute_reply":"2023-03-15T14:04:37.764162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save the initial model","metadata":{}},{"cell_type":"code","source":"# torch.save(model.state_dict(), 'initial_weight.pth')","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:37.768082Z","iopub.execute_input":"2023-03-15T14:04:37.768405Z","iopub.status.idle":"2023-03-15T14:04:37.84592Z","shell.execute_reply.started":"2023-03-15T14:04:37.768367Z","shell.execute_reply":"2023-03-15T14:04:37.845027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"code","source":"# Fine tuning\n# set_parameter_requires_grad(model, False)\n# model, num_epochs, best_epoch, histories = train_model(model, device, dataloaders_dict, criterion, optimizer, exp_lr_scheduler, num_epochs=100, is_inception=False)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:37.847906Z","iopub.execute_input":"2023-03-15T14:04:37.848621Z","iopub.status.idle":"2023-03-15T14:04:37.853362Z","shell.execute_reply.started":"2023-03-15T14:04:37.848583Z","shell.execute_reply":"2023-03-15T14:04:37.852291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot(num_epochs, histories)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:37.858834Z","iopub.execute_input":"2023-03-15T14:04:37.859414Z","iopub.status.idle":"2023-03-15T14:04:37.864634Z","shell.execute_reply.started":"2023-03-15T14:04:37.859387Z","shell.execute_reply":"2023-03-15T14:04:37.863713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save(model.state_dict(), 'fine_tuned.pth')","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:37.865836Z","iopub.execute_input":"2023-03-15T14:04:37.866266Z","iopub.status.idle":"2023-03-15T14:04:37.874845Z","shell.execute_reply.started":"2023-03-15T14:04:37.866232Z","shell.execute_reply":"2023-03-15T14:04:37.874018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set_parameter_requires_grad(model, True)\nmodel, num_epochs, best_epoch, histories, augumented, best_score, time_elapsed, f1_macro, classification_reports = train_model(model, device, dataloader_dict, criterion, optimizer, scheduler, num_epochs=17, is_inception=False, augumented=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T14:04:37.87647Z","iopub.execute_input":"2023-03-15T14:04:37.876887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(num_epochs, histories)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define dataset class\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, img_labels: pd.DataFrame, img_dir, transform=None, target_transform=None):\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n        self.img_labels = img_labels\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0] + \".png\")\n        image = read_image(img_path)\n        label = self.img_labels.iloc[idx, 1]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return image, label, idx# Save the model","metadata":{}},{"cell_type":"code","source":"torch.save(model, \"densenet121-augmented.pth\") # save the entire model with weight parameters, trained with train data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(best_epoch)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}